{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87487096-99f9-466a-9737-de5d79a05c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233b118d-0d70-40ab-8669-15627c093646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/04 13:26:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/04 13:26:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://599ece5cb81e:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>paisesTorres</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7d13e5a0e0b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"paisesTorres\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2e6b4a-d4e1-4fac-bf20-7c190568cf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id,equipo,sigla',\n",
       " '1,30. Februar,AUT',\n",
       " '2,A North American Team,MEX',\n",
       " '3,Acipactli,MEX',\n",
       " '4,Acturus,ARG']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_paises = spark.sparkContext.textFile(\"/home/jovyan/data/paises.csv\")\n",
    "rdd_paises.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d5f3aa-8b1c-483c-aba3-2da2f0534580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '30. Februar', 'AUT'],\n",
       " ['2', 'A North American Team', 'MEX'],\n",
       " ['3', 'Acipactli', 'MEX'],\n",
       " ['4', 'Acturus', 'ARG'],\n",
       " ['5', 'Afghanistan', 'AFG']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = rdd_paises.first()\n",
    "rdd_paises2 = rdd_paises.filter(lambda x: x != header).map(lambda x: x.split(\",\"))\n",
    "rdd_paises2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "540682c3-d2cb-48c4-b088-5b98c88f65ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'equipo', 'sigla'],\n",
       " ['1', '30. Februar', 'AUT'],\n",
       " ['2', 'A North American Team', 'MEX'],\n",
       " ['3', 'Acipactli', 'MEX'],\n",
       " ['4', 'Acturus', 'ARG']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_paises2 = rdd_paises.map(lambda x: x.split(\",\"))\n",
    "rdd_paises2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae6b79d9-4b0c-4073-97c9-01271abdb739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '30. Februar', 'AUT'],\n",
       " ['2', 'A North American Team', 'MEX'],\n",
       " ['3', 'Acipactli', 'MEX'],\n",
       " ['4', 'Acturus', 'ARG'],\n",
       " ['5', 'Afghanistan', 'AFG']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = rdd_paises.first()\n",
    "rdd_paises2 = rdd_paises.filter(lambda x: x != header).map(lambda x: x.split(\",\"))\n",
    "rdd_paises2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "785ab891-b77a-4ad7-af6a-2fa4c27d8556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '30. Februar', 'AUT'),\n",
       " (2, 'A North American Team', 'MEX'),\n",
       " (3, 'Acipactli', 'MEX'),\n",
       " (4, 'Acturus', 'ARG'),\n",
       " (5, 'Afghanistan', 'AFG')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_paises3 = rdd_paises2.map(lambda x: (\n",
    "    int(x[0]),     # id_pais\n",
    "    x[1],          # nombre\n",
    "    x[2]           # continente\n",
    "))\n",
    "rdd_paises3.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3dc3551-b41b-4804-b113-867bf4b0be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_paises = StructType([\n",
    "    StructField(\"id_pais\", IntegerType(), False),\n",
    "    StructField(\"nombre_pais\", StringType(), False),\n",
    "    StructField(\"continente\", StringType(), False)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "926cc0ca-aa03-4564-a0ae-631f2ec90591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id_pais: int, nombre_pais: string, continente: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paises = spark.createDataFrame(rdd_paises3, schema=schema_paises)\n",
    "df_paises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16bd64c6-882f-44fd-8a0c-139682e3fdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_pais: integer (nullable = false)\n",
      " |-- nombre_pais: string (nullable = false)\n",
      " |-- continente: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_paises.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e2e3ad3-45dd-47ff-8f38-584099b4847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+\n",
      "|id_pais|         nombre_pais|continente|\n",
      "+-------+--------------------+----------+\n",
      "|      1|         30. Februar|       AUT|\n",
      "|      2|A North American ...|       MEX|\n",
      "|      3|           Acipactli|       MEX|\n",
      "|      4|             Acturus|       ARG|\n",
      "|      5|         Afghanistan|       AFG|\n",
      "+-------+--------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_paises.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa682cae-4203-4e2b-8b9d-46ec3b48c257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',nombre_juego,annio,temporada,ciudad',\n",
       " '1,1896 Verano,1896,Verano,Athina',\n",
       " '2,1900 Verano,1900,Verano,Paris',\n",
       " '3,1904 Verano,1904,Verano,St. Louis',\n",
       " '4,1906 Verano,1906,Verano,Athina']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Leer el archivo\n",
    "rdd_juegos = spark.sparkContext.textFile(\"/home/jovyan/data/juegos.csv\")\n",
    "rdd_juegos.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7f1bbce-86aa-44c0-adc4-3411f07b9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Quitar encabezado\n",
    "header_j = rdd_juegos.first()\n",
    "rdd_juegos2 = rdd_juegos.filter(lambda x: x != header_j).map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49e1ff7e-1e6e-4190-9b25-667ed9513de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Convertir tipos\n",
    "rdd_juegos3 = rdd_juegos2.map(lambda x: (\n",
    "    int(x[0]),   # id_juego\n",
    "    x[1],        # nombre_juego\n",
    "    x[2],        # anio\n",
    "    x[3],        # temporada\n",
    "    x[4]         # ciudad\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e51779b-3d39-4d76-a101-a6f0ded4e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Crear schema\n",
    "schema_juegos = StructType([\n",
    "    StructField(\"id_juego\", IntegerType(), False),\n",
    "    StructField(\"nombre_juego\", StringType(), False),\n",
    "    StructField(\"anio\", StringType(), False),\n",
    "    StructField(\"temporada\", StringType(), False),\n",
    "    StructField(\"ciudad\", StringType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2230fc51-6536-4922-b6b4-9e212372007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Crear DataFrame\n",
    "df_juegos = spark.createDataFrame(rdd_juegos3, schema=schema_juegos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4160f64e-c80a-42bd-979d-71833f81879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_juego: integer (nullable = false)\n",
      " |-- nombre_juego: string (nullable = false)\n",
      " |-- anio: string (nullable = false)\n",
      " |-- temporada: string (nullable = false)\n",
      " |-- ciudad: string (nullable = false)\n",
      "\n",
      "+--------+-------------+----+---------+------------+\n",
      "|id_juego| nombre_juego|anio|temporada|      ciudad|\n",
      "+--------+-------------+----+---------+------------+\n",
      "|       1|  1896 Verano|1896|   Verano|      Athina|\n",
      "|       2|  1900 Verano|1900|   Verano|       Paris|\n",
      "|       3|  1904 Verano|1904|   Verano|   St. Louis|\n",
      "|       4|  1906 Verano|1906|   Verano|      Athina|\n",
      "|       5|  1908 Verano|1908|   Verano|      London|\n",
      "|       6|  1912 Verano|1912|   Verano|   Stockholm|\n",
      "|       7|  1920 Verano|1920|   Verano|   Antwerpen|\n",
      "|       8|1924 Invierno|1924| Invierno|    Chamonix|\n",
      "|       9|  1924 Verano|1924|   Verano|       Paris|\n",
      "|      10|1928 Invierno|1928| Invierno|Sankt Moritz|\n",
      "+--------+-------------+----+---------+------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# 6) Mostrar resultados\n",
    "df_juegos.printSchema()\n",
    "df_juegos.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dff882f-4f1c-4f7c-be85-1c4b00af576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo cargado:\n",
      "['resultado_id,medalla,deportista_id,juego_id,evento_id', '1,NA,1,39,1', '2,NA,2,49,2', '3,NA,3,7,3', '4,Gold,4,2,4']\n"
     ]
    }
   ],
   "source": [
    "# 1. Leer archivo\n",
    "rdd_resultados = spark.sparkContext.textFile(\"/home/jovyan/data/resultados.csv\")\n",
    "print(\"Archivo cargado:\")\n",
    "print(rdd_resultados.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5fb5041-0d7e-45e9-8fa0-5f010bb17f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Quitar encabezado\n",
    "header = rdd_resultados.first()\n",
    "rdd_resultados2 = rdd_resultados.filter(lambda x: x != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76eb26e0-d403-4bdc-b984-62129a87c427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después del split:\n",
      "[['1', 'NA', '1', '39', '1'], ['2', 'NA', '2', '49', '2'], ['3', 'NA', '3', '7', '3'], ['4', 'Gold', '4', '2', '4'], ['5', 'NA', '5', '36', '5']]\n"
     ]
    }
   ],
   "source": [
    "# 3. Separar por comas\n",
    "rdd_resultados3 = rdd_resultados2.map(lambda x: x.split(\",\"))\n",
    "print(\"Después del split:\")\n",
    "print(rdd_resultados3.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfbf69a9-a1c8-49de-82a1-28a2e7e5afd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casteado final:\n",
      "[(1, 'NA', 1, 39, 1), (2, 'NA', 2, 49, 2), (3, 'NA', 3, 7, 3), (4, 'Gold', 4, 2, 4), (5, 'NA', 5, 36, 5)]\n"
     ]
    }
   ],
   "source": [
    "# 4. Convertir tipos\n",
    "rdd_resultados_final = rdd_resultados3.map(lambda x: (\n",
    "    int(x[0]),  # resultado_id\n",
    "    x[1],       # medalla\n",
    "    int(x[2]),  # deportista_id\n",
    "    int(x[3]),  # juego_id\n",
    "    int(x[4])   # evento_id\n",
    "))\n",
    "\n",
    "print(\"Casteado final:\")\n",
    "print(rdd_resultados_final.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f897ade-be34-46d1-8984-e84877de929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Schema\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema_resultados_Torres = StructType([\n",
    "    StructField(\"resultado_id\", IntegerType(), False),\n",
    "    StructField(\"medalla\", StringType(), False),\n",
    "    StructField(\"deportista_id\", IntegerType(), False),\n",
    "    StructField(\"juego_id\", IntegerType(), False),\n",
    "    StructField(\"evento_id\", IntegerType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01ab86c2-51f4-4f24-bd0f-f92c4c876a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Crear DataFrame\n",
    "df_resultados_Torres = spark.createDataFrame(rdd_resultados_final, schema=schema_resultados_Torres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b86b299-e4b3-4382-9ce9-545f323c1341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- resultado_id: integer (nullable = false)\n",
      " |-- medalla: string (nullable = false)\n",
      " |-- deportista_id: integer (nullable = false)\n",
      " |-- juego_id: integer (nullable = false)\n",
      " |-- evento_id: integer (nullable = false)\n",
      "\n",
      "+------------+-------+-------------+--------+---------+\n",
      "|resultado_id|medalla|deportista_id|juego_id|evento_id|\n",
      "+------------+-------+-------------+--------+---------+\n",
      "|           1|     NA|            1|      39|        1|\n",
      "|           2|     NA|            2|      49|        2|\n",
      "|           3|     NA|            3|       7|        3|\n",
      "|           4|   Gold|            4|       2|        4|\n",
      "|           5|     NA|            5|      36|        5|\n",
      "|           6|     NA|            5|      36|        6|\n",
      "|           7|     NA|            5|      38|        5|\n",
      "|           8|     NA|            5|      38|        6|\n",
      "|           9|     NA|            5|      40|        5|\n",
      "|          10|     NA|            5|      40|        6|\n",
      "+------------+-------+-------------+--------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# 7. Ver salidas\n",
    "df_resultados_Torres.printSchema()\n",
    "df_resultados_Torres.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de93f5cf-933e-44eb-8bcd-e63dc1f08c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo deporte.csv cargado:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deporte_id,deporte', '1,Basketball', '2,Judo', '3,Football', '4,Tug-Of-War']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# === 1. Leer archivo ===\n",
    "rdd_deporte = spark.sparkContext.textFile(\"/home/jovyan/data/deporte.csv\")\n",
    "print(\"Archivo deporte.csv cargado:\")\n",
    "print(rdd_deporte.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3217a7-670d-4a02-80fc-6a63e2100d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Quitar encabezado ===\n",
    "header_deporte = rdd_deporte.first()\n",
    "rdd_deporte2 = rdd_deporte.filter(lambda x: x != header_deporte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a734442f-da54-4111-8a5b-1a1de72a5e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después del split:\n",
      "[['1', 'Basketball'], ['2', 'Judo'], ['3', 'Football'], ['4', 'Tug-Of-War'], ['5', 'Speed Skating']]\n"
     ]
    }
   ],
   "source": [
    "# === 3. Separar columnas ===\n",
    "rdd_deporte3 = rdd_deporte2.map(lambda x: x.split(\",\"))\n",
    "print(\"Después del split:\")\n",
    "print(rdd_deporte3.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d28973-80f3-4324-b774-9352b344e5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casteo final:\n",
      "[(1, 'Basketball'), (2, 'Judo'), (3, 'Football'), (4, 'Tug-Of-War'), (5, 'Speed Skating')]\n"
     ]
    }
   ],
   "source": [
    "# === 4. Casteo de datos ===\n",
    "# Estructura real del archivo:\n",
    "# deporte_id, deporte\n",
    "rdd_deporte_final = rdd_deporte3.map(lambda x: (\n",
    "    int(x[0]),   # deporte_id\n",
    "    x[1]         # nombre_deporte\n",
    "))\n",
    "\n",
    "print(\"Casteo final:\")\n",
    "print(rdd_deporte_final.take(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdcd4b91-3d33-40fb-ab4c-781ea3f44fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Crear Schema ===\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema_deporte_Torres = StructType([\n",
    "    StructField(\"deporte_id\", IntegerType(), False),\n",
    "    StructField(\"nombre_deporte\", StringType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e66f635-f2e2-408a-bbbb-e6c4aea5732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Crear DataFrame ===\n",
    "df_deporte_Torres = spark.createDataFrame(rdd_deporte_final, schema=schema_deporte_Torres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5647ca4-e571-450f-a249-ec06ca0155b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- deporte_id: integer (nullable = false)\n",
      " |-- nombre_deporte: string (nullable = false)\n",
      "\n",
      "+----------+--------------+\n",
      "|deporte_id|nombre_deporte|\n",
      "+----------+--------------+\n",
      "|         1|    Basketball|\n",
      "|         2|          Judo|\n",
      "|         3|      Football|\n",
      "|         4|    Tug-Of-War|\n",
      "|         5| Speed Skating|\n",
      "+----------+--------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# === 7. Verificar ===\n",
    "df_deporte_Torres.printSchema()\n",
    "df_deporte_Torres.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4df6025-5839-4370-8676-e07d0212338f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['evento_id,evento,deporte_id',\n",
       " \"1,Basketball Men's Basketball,1\",\n",
       " \"2,Judo Men's Extra-Lightweight,2\",\n",
       " \"3,Football Men's Football,3\",\n",
       " \"4,Tug-Of-War Men's Tug-Of-War,4\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_evento = spark.sparkContext.textFile(\"/home/jovyan/data/evento.csv\")\n",
    "rdd_evento.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70521751-c89b-49cf-8ba8-192a8a65f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = rdd_evento.first()\n",
    "rdd_evento2 = rdd_evento.filter(lambda x: x != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89037228-37ce-4908-b476-51bdedb97367",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_evento3 = rdd_evento2.map(lambda x: x.replace('\"', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6edb4e-5ec7-49b6-9826-9f028dfd873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_evento4 = rdd_evento3.map(lambda x: x.split(\",\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c6178c-f188-4006-8939-9efdb20b1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_evento(row):\n",
    "    try:\n",
    "        return (int(row[0]), row[1], int(row[2]))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "rdd_evento5 = rdd_evento4.map(limpiar_evento).filter(lambda x: x is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cab48a9-e8a4-4443-b385-58e2c43d9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema_evento = StructType([\n",
    "    StructField(\"evento_id\", IntegerType(), False),\n",
    "    StructField(\"nombre_evento\", StringType(), False),\n",
    "    StructField(\"deporte_id\", IntegerType(), False)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f4a1a2d-d9a8-4ebb-ba7c-8d3aaafdd2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evento_Torres = spark.createDataFrame(rdd_evento5, schema_evento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2055e42-aa81-4cfa-a337-5dac74a90f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- evento_id: integer (nullable = false)\n",
      " |-- nombre_evento: string (nullable = false)\n",
      " |-- deporte_id: integer (nullable = false)\n",
      "\n",
      "+---------+--------------------+----------+\n",
      "|evento_id|       nombre_evento|deporte_id|\n",
      "+---------+--------------------+----------+\n",
      "|        1|Basketball Men's ...|         1|\n",
      "|        2|Judo Men's Extra-...|         2|\n",
      "|        3|Football Men's Fo...|         3|\n",
      "|        4|Tug-Of-War Men's ...|         4|\n",
      "|        5|Speed Skating Wom...|         5|\n",
      "|        7|Cross Country Ski...|         6|\n",
      "|        8|Cross Country Ski...|         6|\n",
      "|        9|Cross Country Ski...|         6|\n",
      "|       10|Cross Country Ski...|         6|\n",
      "|       11|Cross Country Ski...|         6|\n",
      "+---------+--------------------+----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "df_evento_Torres.printSchema()\n",
    "df_evento_Torres.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ad4d9-69c3-473d-913f-b3df36085ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
